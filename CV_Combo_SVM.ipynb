{
 "metadata": {
  "name": "",
  "signature": "sha256:67659c45c339293856ea7daf92dffd3e592c8a18991a0077b023e9f5d2e90ae2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import cross_validation\n",
      "import pylab as plt\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.metrics import classification_report\n",
      "import gc\n",
      "import pickle\n",
      "import math\n",
      "from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "%matplotlib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Write to csv files.  This is in the windows filesystem.\n",
      "y_train_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\y_train_df.csv', index_col=0)\n",
      "x_train_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\x_train_df.csv', index_col=0)\n",
      "x_train_hu_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\x_train_hu_big_df.csv', index_col=0)\n",
      "x_total = pd.concat([x_train_hu_df, x_train_df], axis=1).iloc[:,:48]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(x_train_hu_df, y_train_df, test_size=0.15, random_state=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(4551L, 36L)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(25783L, 36L)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_ADA = AdaBoostClassifier(DecisionTreeClassifier(max_depth=16), n_estimators=100, learning_rate=.125)\n",
      "clf_RF = RandomForestClassifier(n_estimators=200, n_jobs=2)\n",
      "clf_SVM = SVC(C=100000, class_weight = 'auto', gamma=.01, probability=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_ADA.fit(X_train, np.ravel(y_train))\n",
      "clf_RF.fit(X_train, np.ravel(y_train))\n",
      "clf_SVM.fit(X_train, np.ravel(y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "SVC(C=100000, cache_size=200, class_weight='auto', coef0=0.0, degree=3,\n",
        "  gamma=0.01, kernel='rbf', max_iter=-1, probability=True,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Bias...\"\n",
      "results_ADA = clf_ADA.predict_proba(X_train)\n",
      "results_RF = clf_RF.predict_proba(X_train)\n",
      "results_SVM = clf_SVM.predict_proba(X_train)\n",
      "print clf_ADA.score(X_train, y_train)\n",
      "print clf_RF.score(X_train, y_train)\n",
      "#print clf_SVM.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bias...\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Variance...\"\n",
      "results_ADA_test = clf_ADA.predict_proba(X_test)\n",
      "results_RF_test = clf_RF.predict_proba(X_test)\n",
      "#results_SVM_test = clf_SVM.predict_proba(X_test)\n",
      "print clf_ADA.score(X_test, y_test)\n",
      "print clf_RF.score(X_test, y_test)\n",
      "print clf_SVM.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variance...\n",
        "0.561634805537"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.552186332674"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.11470006592"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_total = np.concatenate([results_ADA, results_RF], axis=1 )\n",
      "results_total_test = np.concatenate([results_ADA_test, results_RF_test], axis=1 )\n",
      "print results_total.shape\n",
      "print results_total_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(25783L, 242L)\n",
        "(4551L, 242L)\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_logistic = LogisticRegression(penalty='l2', class_weight='auto', fit_intercept=True, C=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_logistic.fit(results_total, np.ravel(y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "LogisticRegression(C=10, class_weight='auto', dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_logistic.score(results_total_test, np.ravel(y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 194,
       "text": [
        "0.56405185673478353"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = clf_logistic.predict_proba(results_total_test)\n",
      "#results = (results_RF_test + results_ADA_test)/2.0\n",
      "results_norm = results*1.0 + np.ones(results.shape)*(1.0/121)*0.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(results_norm[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 203,
       "text": [
        "0.99999999999999989"
       ]
      }
     ],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_predicted = [results_norm[i,int(y_test[i])] for i in xrange(len(results_norm))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(np.log(results_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 205,
       "text": [
        "-2.4247952688893166"
       ]
      }
     ],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(np.log(results_predicted)).describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 4551.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>   -2.424795</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    2.788495</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   -9.972353</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   -4.598128</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>   -0.876964</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>   -0.010785</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>   -0.004256</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "                 0\n",
        "count  4551.000000\n",
        "mean     -2.424795\n",
        "std       2.788495\n",
        "min      -9.972353\n",
        "25%      -4.598128\n",
        "50%      -0.876964\n",
        "75%      -0.010785\n",
        "max      -0.004256"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(np.log(results_predicted), bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 207,
       "text": [
        "(array([  5.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n",
        "          5.00000000e+00,   7.00000000e+00,   1.10000000e+01,\n",
        "          1.10000000e+01,   2.00000000e+01,   1.00000000e+01,\n",
        "          1.30000000e+01,   1.20000000e+01,   2.10000000e+01,\n",
        "          1.10000000e+01,   1.60000000e+01,   2.00000000e+01,\n",
        "          1.90000000e+01,   1.80000000e+01,   1.20000000e+01,\n",
        "          1.30000000e+01,   2.20000000e+01,   1.80000000e+01,\n",
        "          1.70000000e+01,   1.10000000e+01,   2.10000000e+01,\n",
        "          1.30000000e+01,   1.80000000e+01,   2.00000000e+01,\n",
        "          9.00000000e+00,   1.50000000e+01,   1.60000000e+01,\n",
        "          2.30000000e+01,   1.50000000e+01,   1.20000000e+01,\n",
        "          1.30000000e+01,   1.40000000e+01,   1.70000000e+01,\n",
        "          1.20000000e+01,   2.10000000e+01,   1.60000000e+01,\n",
        "          2.20000000e+01,   2.40000000e+01,   1.40000000e+01,\n",
        "          2.20000000e+01,   1.80000000e+01,   1.70000000e+01,\n",
        "          2.60000000e+01,   2.20000000e+01,   3.40000000e+01,\n",
        "          3.70000000e+01,   3.50000000e+01,   7.80000000e+01,\n",
        "          9.60000000e+01,   7.30000000e+01,   7.50000000e+01,\n",
        "          7.60000000e+01,   5.50000000e+01,   5.20000000e+01,\n",
        "          4.90000000e+01,   4.40000000e+01,   4.50000000e+01,\n",
        "          4.60000000e+01,   4.50000000e+01,   3.10000000e+01,\n",
        "          2.80000000e+01,   4.80000000e+01,   2.60000000e+01,\n",
        "          3.10000000e+01,   3.00000000e+01,   3.90000000e+01,\n",
        "          2.40000000e+01,   3.30000000e+01,   2.70000000e+01,\n",
        "          2.00000000e+01,   3.30000000e+01,   1.80000000e+01,\n",
        "          1.80000000e+01,   2.10000000e+01,   1.80000000e+01,\n",
        "          2.60000000e+01,   1.50000000e+01,   1.80000000e+01,\n",
        "          1.90000000e+01,   1.70000000e+01,   2.80000000e+01,\n",
        "          1.80000000e+01,   2.10000000e+01,   1.70000000e+01,\n",
        "          2.70000000e+01,   1.50000000e+01,   1.40000000e+01,\n",
        "          2.90000000e+01,   3.40000000e+01,   3.00000000e+01,\n",
        "          3.40000000e+01,   3.60000000e+01,   3.90000000e+01,\n",
        "          4.70000000e+01,   6.90000000e+01,   1.21000000e+02,\n",
        "          1.87700000e+03]),\n",
        " array([ -9.97235332e+00,  -9.87267235e+00,  -9.77299138e+00,\n",
        "         -9.67331040e+00,  -9.57362943e+00,  -9.47394846e+00,\n",
        "         -9.37426749e+00,  -9.27458651e+00,  -9.17490554e+00,\n",
        "         -9.07522457e+00,  -8.97554359e+00,  -8.87586262e+00,\n",
        "         -8.77618165e+00,  -8.67650068e+00,  -8.57681970e+00,\n",
        "         -8.47713873e+00,  -8.37745776e+00,  -8.27777679e+00,\n",
        "         -8.17809581e+00,  -8.07841484e+00,  -7.97873387e+00,\n",
        "         -7.87905289e+00,  -7.77937192e+00,  -7.67969095e+00,\n",
        "         -7.58000998e+00,  -7.48032900e+00,  -7.38064803e+00,\n",
        "         -7.28096706e+00,  -7.18128608e+00,  -7.08160511e+00,\n",
        "         -6.98192414e+00,  -6.88224317e+00,  -6.78256219e+00,\n",
        "         -6.68288122e+00,  -6.58320025e+00,  -6.48351928e+00,\n",
        "         -6.38383830e+00,  -6.28415733e+00,  -6.18447636e+00,\n",
        "         -6.08479538e+00,  -5.98511441e+00,  -5.88543344e+00,\n",
        "         -5.78575247e+00,  -5.68607149e+00,  -5.58639052e+00,\n",
        "         -5.48670955e+00,  -5.38702858e+00,  -5.28734760e+00,\n",
        "         -5.18766663e+00,  -5.08798566e+00,  -4.98830468e+00,\n",
        "         -4.88862371e+00,  -4.78894274e+00,  -4.68926177e+00,\n",
        "         -4.58958079e+00,  -4.48989982e+00,  -4.39021885e+00,\n",
        "         -4.29053788e+00,  -4.19085690e+00,  -4.09117593e+00,\n",
        "         -3.99149496e+00,  -3.89181398e+00,  -3.79213301e+00,\n",
        "         -3.69245204e+00,  -3.59277107e+00,  -3.49309009e+00,\n",
        "         -3.39340912e+00,  -3.29372815e+00,  -3.19404718e+00,\n",
        "         -3.09436620e+00,  -2.99468523e+00,  -2.89500426e+00,\n",
        "         -2.79532328e+00,  -2.69564231e+00,  -2.59596134e+00,\n",
        "         -2.49628037e+00,  -2.39659939e+00,  -2.29691842e+00,\n",
        "         -2.19723745e+00,  -2.09755647e+00,  -1.99787550e+00,\n",
        "         -1.89819453e+00,  -1.79851356e+00,  -1.69883258e+00,\n",
        "         -1.59915161e+00,  -1.49947064e+00,  -1.39978967e+00,\n",
        "         -1.30010869e+00,  -1.20042772e+00,  -1.10074675e+00,\n",
        "         -1.00106577e+00,  -9.01384802e-01,  -8.01703829e-01,\n",
        "         -7.02022856e-01,  -6.02341884e-01,  -5.02660911e-01,\n",
        "         -4.02979938e-01,  -3.03298965e-01,  -2.03617993e-01,\n",
        "         -1.03937020e-01,  -4.25604704e-03]),\n",
        " <a list of 100 Patch objects>)"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(results_norm[4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 213,
       "text": [
        "[<matplotlib.lines.Line2D at 0x16f8d9a20>]"
       ]
      }
     ],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
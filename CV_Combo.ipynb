{
 "metadata": {
  "name": "",
  "signature": "sha256:d1d73935845a7b02744dce2e56cc29584d0a121a8911ce00c9e9b0bc625693a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import cross_validation\n",
      "import pylab as plt\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.metrics import classification_report\n",
      "import gc\n",
      "import pickle\n",
      "import math\n",
      "from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "%matplotlib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Write to csv files.  This is in the windows filesystem.\n",
      "y_train_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\y_train_df.csv', index_col=0)\n",
      "x_train_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\x_train_hu_facs_df.csv', index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(x_train_df, y_train_df, test_size=0.6, random_state=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "(18201L, 66L)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(12133L, 66L)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_ADA = AdaBoostClassifier(DecisionTreeClassifier(max_depth=8), n_estimators=400, learning_rate=.05)\n",
      "clf_RF = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "#clf_SVM = SVC(C=100000, class_weight = 'auto', gamma=.01, probability=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Training ADA...\"\n",
      "clf_ADA.fit(X_train, np.ravel(y_train))\n",
      "print \"Training RF...\"\n",
      "clf_RF.fit(X_train, np.ravel(y_train))\n",
      "#clf_SVM.fit(X_train, np.ravel(y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training ADA...\n",
        "Training RF..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=100, n_jobs=2,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Bias...\"\n",
      "print clf_ADA.score(X_train, y_train)\n",
      "print clf_RF.score(X_train, y_train)\n",
      "#print clf_SVM.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bias...\n",
        "0.909503008324"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Variance...\"\n",
      "results_ADA = clf_ADA.predict_proba(X_test)\n",
      "results_RF = clf_RF.predict_proba(X_test)\n",
      "#results_SVM = clf_SVM.predict_proba(X_train)\n",
      "print clf_ADA.score(X_test, y_test)\n",
      "print clf_RF.score(X_test, y_test)\n",
      "#print clf_SVM.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variance...\n",
        "0.501346079886"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.527004010769"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Variance...\"\n",
      "results_ADA_list = clf_ADA.predict(X_test)\n",
      "results_RF_list = clf_RF.predict(X_test)\n",
      "#results_SVM = clf_SVM.predict_proba(X_train)\n",
      "print clf_ADA.score(X_test, y_test)\n",
      "print clf_RF.score(X_test, y_test)\n",
      "#print clf_SVM.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variance...\n",
        "0.501346079886"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.527004010769"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "agree_list = np.zeros(results_ADA_list.shape)\n",
      "RF_agree = np.zeros(results_ADA_list.shape)\n",
      "for i in range(len(results_ADA)):\n",
      "    if results_ADA_list[i]==results_RF_list[i]:\n",
      "        agree_list[i] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(agree_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "12034.0"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_total = np.concatenate([results_ADA, results_RF], axis=1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_mix = LogisticRegression(penalty='l1', class_weight='auto', C=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_mix.fit(results_total, np.ravel(y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_mix.score(results_total, np.ravel(y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ada_weight = .52\n",
      "rf_weight = 1 - ada_weight\n",
      "results = ada_weight*results_ADA + rf_weight*results_RF\n",
      "sum(results[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.99999999999999911"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mix_weight = 1\n",
      "uniform_weight = 1- mix_weight\n",
      "results_uniform = results*mix_weight + np.ones(results.shape)*(1.0/121)*uniform_weight\n",
      "sum(results_uniform[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.99999999999999911"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_predicted = [results_ADA[i,int(y_test[i])] for i in xrange(len(results_ADA))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index 4551 is out of bounds for axis 0 with size 4551",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-18-fa50254b1501>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresults_ADA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_ADA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mIndexError\u001b[0m: index 4551 is out of bounds for axis 0 with size 4551"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(np.log(results_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "-1.6290335601428212"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(np.log(results_predicted), bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "(array([   1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
        "           0.,    0.,    0.,    0.,    0.,    1.,    0.,    1.,    0.,\n",
        "           0.,    1.,    1.,    0.,    0.,    2.,    0.,    4.,    2.,\n",
        "           1.,    0.,    1.,    1.,    0.,    1.,    2.,    1.,    0.,\n",
        "           1.,    2.,    1.,    5.,    2.,    6.,    2.,    7.,    9.,\n",
        "           9.,   14.,   14.,   13.,   10.,   14.,   12.,    9.,   12.,\n",
        "          21.,   16.,   24.,   23.,   21.,   26.,   30.,   29.,   30.,\n",
        "          34.,   41.,   45.,   51.,   41.,   65.,   50.,   56.,   51.,\n",
        "          59.,   67.,   80.,   71.,   75.,   68.,   77.,   81.,   87.,\n",
        "          88.,   95.,   88.,   79.,   84.,   81.,   87.,   87.,   99.,\n",
        "         112.,  117.,  132.,  149.,  160.,  205.,  259.,  285.,  333.,  530.]),\n",
        " array([ -1.10655966e+01,  -1.09549496e+01,  -1.08443026e+01,\n",
        "         -1.07336556e+01,  -1.06230086e+01,  -1.05123615e+01,\n",
        "         -1.04017145e+01,  -1.02910675e+01,  -1.01804205e+01,\n",
        "         -1.00697735e+01,  -9.95912649e+00,  -9.84847948e+00,\n",
        "         -9.73783247e+00,  -9.62718545e+00,  -9.51653844e+00,\n",
        "         -9.40589143e+00,  -9.29524442e+00,  -9.18459741e+00,\n",
        "         -9.07395040e+00,  -8.96330339e+00,  -8.85265638e+00,\n",
        "         -8.74200937e+00,  -8.63136236e+00,  -8.52071534e+00,\n",
        "         -8.41006833e+00,  -8.29942132e+00,  -8.18877431e+00,\n",
        "         -8.07812730e+00,  -7.96748029e+00,  -7.85683328e+00,\n",
        "         -7.74618627e+00,  -7.63553926e+00,  -7.52489225e+00,\n",
        "         -7.41424524e+00,  -7.30359822e+00,  -7.19295121e+00,\n",
        "         -7.08230420e+00,  -6.97165719e+00,  -6.86101018e+00,\n",
        "         -6.75036317e+00,  -6.63971616e+00,  -6.52906915e+00,\n",
        "         -6.41842214e+00,  -6.30777513e+00,  -6.19712811e+00,\n",
        "         -6.08648110e+00,  -5.97583409e+00,  -5.86518708e+00,\n",
        "         -5.75454007e+00,  -5.64389306e+00,  -5.53324605e+00,\n",
        "         -5.42259904e+00,  -5.31195203e+00,  -5.20130502e+00,\n",
        "         -5.09065801e+00,  -4.98001099e+00,  -4.86936398e+00,\n",
        "         -4.75871697e+00,  -4.64806996e+00,  -4.53742295e+00,\n",
        "         -4.42677594e+00,  -4.31612893e+00,  -4.20548192e+00,\n",
        "         -4.09483491e+00,  -3.98418790e+00,  -3.87354088e+00,\n",
        "         -3.76289387e+00,  -3.65224686e+00,  -3.54159985e+00,\n",
        "         -3.43095284e+00,  -3.32030583e+00,  -3.20965882e+00,\n",
        "         -3.09901181e+00,  -2.98836480e+00,  -2.87771779e+00,\n",
        "         -2.76707078e+00,  -2.65642376e+00,  -2.54577675e+00,\n",
        "         -2.43512974e+00,  -2.32448273e+00,  -2.21383572e+00,\n",
        "         -2.10318871e+00,  -1.99254170e+00,  -1.88189469e+00,\n",
        "         -1.77124768e+00,  -1.66060067e+00,  -1.54995365e+00,\n",
        "         -1.43930664e+00,  -1.32865963e+00,  -1.21801262e+00,\n",
        "         -1.10736561e+00,  -9.96718600e-01,  -8.86071589e-01,\n",
        "         -7.75424578e-01,  -6.64777567e-01,  -5.54130556e-01,\n",
        "         -4.43483545e-01,  -3.32836534e-01,  -2.22189523e-01,\n",
        "         -1.11542512e-01,  -8.95501132e-04]),\n",
        " <a list of 100 Patch objects>)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_predicted[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "0.099998435903330615"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
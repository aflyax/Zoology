{
 "metadata": {
  "name": "",
  "signature": "sha256:033da7193f1ee4e7d4253eff79e51d7b67bbd80301027f65638778b21d864d15"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import cross_validation\n",
      "import pylab as plt\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.metrics import classification_report\n",
      "import gc\n",
      "import pickle\n",
      "import math\n",
      "from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "%matplotlib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Write to csv files.  This is in the windows filesystem.\n",
      "y_train_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\y_train_df.csv', index_col=0)\n",
      "#x_train_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\x_train_df.csv', index_col=0)\n",
      "x_train_hu_df = pd.read_csv('C:\\\\Users\\\\E\\\\Desktop\\\\Zoology_kaggle\\\\x_train_hu_facs_df.csv', index_col=0)\n",
      "#x_total = pd.concat([x_train_hu_df, x_train_df], axis=1).iloc[:,:48]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x_train_hu_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = StandardScaler()\n",
      "x_scaled = scaler.fit_transform(x_train_hu_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(x_scaled).describe().iloc[7,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "0      8.313958\n",
        "1      7.129162\n",
        "2      1.294332\n",
        "3      4.965124\n",
        "4     27.611207\n",
        "5     29.578048\n",
        "6     40.151868\n",
        "7     53.356775\n",
        "8      8.716662\n",
        "9      7.203596\n",
        "10    11.696385\n",
        "11    13.264596\n",
        "12    15.825923\n",
        "13     1.031533\n",
        "14    12.401564\n",
        "...\n",
        "51    5.103811\n",
        "52    6.089703\n",
        "53    4.891305\n",
        "54    5.258453\n",
        "55    5.878169\n",
        "56    4.936468\n",
        "57    5.443775\n",
        "58    4.996127\n",
        "59    5.123011\n",
        "60    5.201433\n",
        "61    5.437909\n",
        "62    5.142399\n",
        "63    6.734043\n",
        "64    5.769136\n",
        "65    4.595840\n",
        "Name: max, Length: 66, dtype: float64"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Training\"\n",
      "# n_estimators is the number of decision trees\n",
      "# max_features also known as m_try is set to the default value of the square root of the number of features\n",
      "clf = SVC(C=100000, class_weight = 'auto', gamma=.01) \n",
      "scores = cross_validation.cross_val_score(clf, x_scaled, np.ravel(y_train_df), cv=5, n_jobs=1)\n",
      "print \"Accuracy of all classes\"\n",
      "print np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training\n",
        "Accuracy of all classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.555567851853\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(np.ravel(y_train_df), n_folds=5)\n",
      "y_pred = np.array(len(y_train_df) * [0])\n",
      "for train, test in kf:\n",
      "    X_train, X_test, y_train, y_test = np.array(x_scaled)[train,:], np.array(x_scaled)[test,:], np.ravel(y_train_df)[train], np.ravel(y_train_df)[test]\n",
      "    clf = SVC(C=100000, class_weight = 'auto', gamma=.01) \n",
      "    clf.fit(X_train, y_train)\n",
      "    y_pred[test] = clf.predict(X_test)\n",
      "    print clf.score(X_test, y_test)\n",
      "print classification_report(np.ravel(y_train_df), y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.561498200851\n",
        "0.554005252791"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.553450831823"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.557246856386"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.551638117412"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.63      0.56      0.59        87\n",
        "        1.0       0.27      0.19      0.22        16\n",
        "        2.0       0.00      0.00      0.00        29\n",
        "        3.0       0.34      0.33      0.34       242\n",
        "        4.0       0.42      0.45      0.43        92\n",
        "        5.0       0.35      0.39      0.37       274\n",
        "        6.0       0.00      0.00      0.00        19\n",
        "        7.0       0.45      0.51      0.48       694\n",
        "        8.0       0.00      0.00      0.00        10\n",
        "        9.0       0.57      0.60      0.59       815\n",
        "       10.0       0.78      0.87      0.82       519\n",
        "       11.0       0.45      0.58      0.51       681\n",
        "       12.0       0.76      0.82      0.79       393\n",
        "       13.0       0.07      0.06      0.07        49\n",
        "       14.0       0.52      0.61      0.56       286\n",
        "       15.0       0.51      0.50      0.50       106\n",
        "       16.0       0.49      0.56      0.52       113\n",
        "       17.0       0.33      0.08      0.12        13\n",
        "       18.0       0.46      0.55      0.50       483\n",
        "       19.0       0.47      0.57      0.52       153\n",
        "       20.0       0.19      0.15      0.16        55\n",
        "       21.0       0.26      0.19      0.22        27\n",
        "       22.0       0.27      0.27      0.27        75\n",
        "       23.0       0.44      0.30      0.36        23\n",
        "       24.0       0.00      0.00      0.00         9\n",
        "       25.0       0.09      0.08      0.08       425\n",
        "       26.0       0.47      0.34      0.39        65\n",
        "       27.0       0.00      0.00      0.00        12\n",
        "       28.0       0.55      0.61      0.58       127\n",
        "       29.0       0.00      0.00      0.00        14\n",
        "       30.0       0.06      0.04      0.05        24\n",
        "       31.0       0.40      0.51      0.45       212\n",
        "       32.0       0.57      0.49      0.52        80\n",
        "       33.0       0.19      0.14      0.17        76\n",
        "       34.0       0.50      0.55      0.52       114\n",
        "       35.0       0.12      0.06      0.09        31\n",
        "       36.0       0.67      0.78      0.72       703\n",
        "       37.0       0.47      0.48      0.48       136\n",
        "       38.0       0.33      0.32      0.32        88\n",
        "       39.0       0.22      0.15      0.18        13\n",
        "       40.0       0.36      0.36      0.36       201\n",
        "       41.0       0.37      0.47      0.41       135\n",
        "       42.0       0.30      0.22      0.25        36\n",
        "       43.0       0.97      0.92      0.95       170\n",
        "       44.0       0.26      0.21      0.23       178\n",
        "       45.0       0.26      0.37      0.30       128\n",
        "       46.0       0.37      0.40      0.39       336\n",
        "       47.0       0.16      0.12      0.14        24\n",
        "       48.0       0.29      0.28      0.28       175\n",
        "       49.0       0.65      0.69      0.67       899\n",
        "       50.0       0.79      0.85      0.82       536\n",
        "       51.0       0.48      0.46      0.47        35\n",
        "       52.0       0.29      0.27      0.28        63\n",
        "       53.0       0.47      0.53      0.50      1172\n",
        "       54.0       0.59      0.49      0.54        96\n",
        "       55.0       0.00      0.00      0.00        10\n",
        "       56.0       0.32      0.23      0.27        30\n",
        "       57.0       0.66      0.64      0.65       372\n",
        "       58.0       0.62      0.70      0.66       694\n",
        "       59.0       0.36      0.25      0.30       131\n",
        "       60.0       0.46      0.43      0.45       439\n",
        "       61.0       0.53      0.57      0.55       678\n",
        "       62.0       0.61      0.56      0.58       500\n",
        "       63.0       0.42      0.33      0.37        96\n",
        "       64.0       0.36      0.10      0.15        42\n",
        "       65.0       0.36      0.31      0.33       132\n",
        "       66.0       0.43      0.38      0.41       141\n",
        "       67.0       0.66      0.71      0.68       236\n",
        "       68.0       0.65      0.60      0.62       123\n",
        "       69.0       0.65      0.62      0.63       113\n",
        "       70.0       0.22      0.20      0.21       108\n",
        "       71.0       0.17      0.05      0.07        21\n",
        "       72.0       0.70      0.72      0.71       385\n",
        "       73.0       0.56      0.53      0.54       625\n",
        "       74.0       0.43      0.34      0.38       158\n",
        "       75.0       0.66      0.71      0.68       229\n",
        "       76.0       0.58      0.68      0.63       190\n",
        "       77.0       0.28      0.19      0.22        64\n",
        "       78.0       0.00      0.00      0.00        16\n",
        "       79.0       0.26      0.27      0.26       363\n",
        "       80.0       0.43      0.39      0.41        61\n",
        "       81.0       0.49      0.39      0.43       173\n",
        "       82.0       0.41      0.16      0.23        43\n",
        "       83.0       0.14      0.07      0.10        14\n",
        "       84.0       0.61      0.50      0.55        38\n",
        "       85.0       0.36      0.38      0.37       914\n",
        "       86.0       0.77      0.84      0.81       352\n",
        "       87.0       0.44      0.41      0.42       174\n",
        "       88.0       0.68      0.64      0.66        56\n",
        "       89.0       0.47      0.42      0.45       511\n",
        "       90.0       0.33      0.14      0.20        14\n",
        "       91.0       0.31      0.34      0.32       417\n",
        "       92.0       0.21      0.16      0.18        38\n",
        "       93.0       0.24      0.22      0.23       150\n",
        "       94.0       0.71      0.75      0.73       412\n",
        "       95.0       0.73      0.73      0.73      1189\n",
        "       96.0       0.23      0.19      0.21       317\n",
        "       97.0       0.39      0.39      0.39        85\n",
        "       98.0       0.36      0.32      0.34       247\n",
        "       99.0       0.38      0.26      0.31       287\n",
        "      100.0       0.55      0.32      0.41        71\n",
        "      101.0       0.03      0.02      0.02        52\n",
        "      102.0       0.13      0.10      0.12        29\n",
        "      103.0       0.42      0.35      0.38        49\n",
        "      104.0       0.59      0.46      0.52       179\n",
        "      105.0       0.61      0.51      0.55        73\n",
        "      106.0       0.08      0.04      0.05        53\n",
        "      107.0       0.53      0.54      0.53       532\n",
        "      108.0       0.63      0.59      0.61      1934\n",
        "      109.0       0.68      0.69      0.68       708\n",
        "      110.0       0.30      0.11      0.16        57\n",
        "      111.0       0.65      0.71      0.68        77\n",
        "      112.0       0.25      0.16      0.20       394\n",
        "      113.0       0.31      0.20      0.25        49\n",
        "      114.0       0.17      0.10      0.12        30\n",
        "      115.0       0.72      0.55      0.63        38\n",
        "      116.0       0.00      0.00      0.00        24\n",
        "      117.0       0.32      0.20      0.25       108\n",
        "      118.0       0.76      0.76      0.76       889\n",
        "      119.0       0.89      0.88      0.88      1979\n",
        "      120.0       0.35      0.28      0.31        54\n",
        "\n",
        "avg / total       0.55      0.56      0.55     30334\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del clf\n",
      "gc.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "6"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(x_scaled, y_train_df, test_size=0.15, random_state=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(4551L, 66L)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(25783L, 66L)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SVC(C=100000, class_weight = 'auto', gamma=.01) #For hu dataset\n",
      "#Auto[C=1, gamma=1/36] = .3535, [C=.1,gamma=1]=.0309, [C=1, gamma=.1]=.38, [C=10, gamma=.2] = .46, [C=100, gamma=.4] = .495\n",
      "#[C=1000, gamma=.8]=.458, [C=1000, gamma = .2]=.49932, [C=1000, gamma = .4]=.49932, [C=1000, gamma = .2]=.5258, \n",
      "#[C=1000, gamma = .1]=.545, #[C=10000, gamma = .1]=.545, #[C=10000, gamma = .05]=.556, #[C=10000, gamma = .01]=.571\n",
      "#[C=10000, gamma = .001]=.521, #[C=100000, gamma = .01]=.58, #[C=1000000, gamma = .01]=.576, #[C=500000, gamma = .1]=.533\n",
      "#[C=500000, gamma = .001]=.533"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(X_train, np.ravel(y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "SVC(C=1, cache_size=200, class_weight='auto', coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#results = clf.predict_proba(X_test)\n",
      "#results = results*.975 + (np.ones(results.shape)/121)*.025\n",
      "clf.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.91025094054221778"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.support_vectors_[:,4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([-0.38775406, -0.36282177, -0.08856659, ..., -0.31295719,\n",
        "       -0.38775406, -0.38775406])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_predicted = [results[i,int(y_test[i])] for i in xrange(len(results))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "object of type 'numpy.float64' has no len()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-14-b702c829315c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(np.log(results_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "-1.725795892498514"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(np.log(results_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[<matplotlib.lines.Line2D at 0x213e6588>]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}